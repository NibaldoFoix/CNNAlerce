{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leemos los datos\n",
    "datos=pd.read_pickle('ALERCE_stamps_2020.pkl', compression='infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuadradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Imagenes no cuadradas: 650\n",
      "\n",
      " Nuevo largo de data: 51594\n"
     ]
    }
   ],
   "source": [
    "#cantidad de imagenes no cuadradas:\n",
    "list_of_indexes=[]\n",
    "for i in range(len(datos['images'])):\n",
    "    if len(datos['images'][i])!=len(datos['images'][i][0]):\n",
    "        list_of_indexes.append(i)\n",
    "\n",
    "cantidad=len(list_of_indexes)\n",
    "\n",
    "sumando=0\n",
    "#creamos este indice ya que al sacar un indice de la lista, todos los indices se resta uno\n",
    "#si vamos del mas pequeño al mas grande\n",
    "for i in list_of_indexes:\n",
    "    #lo sacamos de la data:\n",
    "    datos['images'].pop(i-sumando)\n",
    "    datos['labels'].pop(i-sumando)\n",
    "    datos['metadata'].pop(i-sumando)\n",
    "    sumando+=1\n",
    "        \n",
    "print('# Imagenes no cuadradas: '+str(cantidad))\n",
    "print('\\n Nuevo largo de data: '+str(len(datos['images'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recorte a 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para recortar centros de las imagenes\n",
    "def recorte(imagen):\n",
    "    inicio = imagen[21:42]\n",
    "    recorte = np.zeros([21, 21, 3])\n",
    "    for i in range(len(inicio)):\n",
    "        recorte[i] = inicio[i][21:42]\n",
    "    return recorte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recorte de todas las imagenes\n",
    "dic={'im_21':[]}\n",
    "for i in range(len(datos['images'])):\n",
    "    dic['im_21'].append(recorte(datos['images'][i]))\n",
    "datos.update(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar(matrix,matrix_zero,muestra):\n",
    "    \"\"\" recibe matrix y la devuelve normalizada\n",
    "    \"\"\"\n",
    "    maximo=np.amax(matrix[:,:,muestra])\n",
    "    minimo=np.amin(matrix[:,:,muestra])\n",
    "    matrix_zero[:,:,muestra]=(matrix[:,:,muestra]-minimo)/(maximo-minimo)\n",
    "    return matrix_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalización hecha con exito\n"
     ]
    }
   ],
   "source": [
    "#vamos viendo maximos y minimos, y normalizando\n",
    "\n",
    "#matriz\n",
    "dic={'images':[], 'im_21':[]}\n",
    "\n",
    "contador=1\n",
    "for i in range(len(datos['images'])):\n",
    "    matrix_image=datos['images'][i]\n",
    "    matrix21=datos['im_21'][i]\n",
    "    matriz_zeros_paranormalizar=np.zeros((len(matrix_image),len(matrix_image[0]),3))\n",
    "    matriz_zeros21=np.zeros((len(matrix21),len(matrix21[0]),3))\n",
    "    #3 muestras\n",
    "    for z in range(3):\n",
    "        matriz_zeros_paranormalizar=normalizar(matrix_image, matriz_zeros_paranormalizar, z)\n",
    "        matriz_zeros21=normalizar(matrix21, matriz_zeros21, z)\n",
    "    dic['images'].append(matriz_zeros_paranormalizar)\n",
    "    dic['im_21'].append(matriz_zeros21)\n",
    "    contador+=1\n",
    "\n",
    "datos.update(dic)\n",
    "del(dic)\n",
    "print('Normalización hecha con exito') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nan a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# pixeles == NaN: 74418750\n",
      "Cambiados a 0 con exito\n"
     ]
    }
   ],
   "source": [
    "#Para imagenes de 63:\n",
    "#vemos cuantos datos son NaN y lo cambiamos a 0\n",
    "\n",
    "cantidad=0\n",
    "#matriz\n",
    "for i in range(len(datos['images'])):\n",
    "    array_nan_index=np.argwhere(np.isnan(datos['images'][i]))\n",
    "    for j in array_nan_index:\n",
    "        index_fila=j[0]\n",
    "        index_columna=j[1]\n",
    "        index_muestra=j[2]\n",
    "        datos['images'][i][index_fila][index_columna][index_muestra]=0\n",
    "    cantidad+=len(array_nan_index)\n",
    "        \n",
    "print('# pixeles == NaN: '+str(cantidad))   \n",
    "print('Cambiados a 0 con exito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# pixeles == NaN: 3394818\n",
      "Cambiados a 0 con exito\n"
     ]
    }
   ],
   "source": [
    "#Para imagenes de 21:\n",
    "#vemos cuantos datos son NaN y lo cambiamos a 0\n",
    "\n",
    "cantidad=0\n",
    "#matriz\n",
    "for i in range(len(datos['im_21'])):\n",
    "    array_nan_index=np.argwhere(np.isnan(datos['im_21'][i]))\n",
    "    for j in array_nan_index:\n",
    "        index_fila=j[0]\n",
    "        index_columna=j[1]\n",
    "        index_muestra=j[2]\n",
    "        datos['im_21'][i][index_fila][index_columna][index_muestra]=0\n",
    "    cantidad+=len(array_nan_index)\n",
    "        \n",
    "print('# pixeles == NaN: '+str(cantidad))   \n",
    "print('Cambiados a 0 con exito')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrega lista con los indices de las instancias de cierta categoria de objeto astronomico\n",
    "def get_index_cat(dic_datos, cat):\n",
    "    index_list = []\n",
    "    for i in range(len(dic_datos['labels'])):\n",
    "        if dic_datos['labels'][i]==cat:\n",
    "            index_list.append(i)\n",
    "    return index_list\n",
    "\n",
    "# Genera listas de índices para train, validation y test\n",
    "def get_sets_index(dic_datos):\n",
    "    val_index=np.array([])\n",
    "    test_index=np.array([])\n",
    "    train_index=np.array([])\n",
    "    for k in range (5):\n",
    "        L=get_index_cat(dic_datos, k)\n",
    "        random.shuffle(L)\n",
    "        test_index=np.append(test_index,L[0:200])\n",
    "        val_index=np.append(val_index,L[200:300])\n",
    "\n",
    "        if k == 1:\n",
    "            for j in range (11):\n",
    "                train_index=np.append(train_index,L[300:])\n",
    "            train_index=np.append(train_index,L[300:486])\n",
    "        else:\n",
    "            train_index=np.append(train_index,L[300:])\n",
    "            if k == 2:\n",
    "                train_index=np.append(train_index,L[300:319])\n",
    "            if k == 3:\n",
    "                train_index=np.append(train_index,L[300:5243])                    \n",
    "            if k == 4:\n",
    "                train_index=np.append(train_index,L[300:4308])\n",
    "                    \n",
    "    random.shuffle(test_index)\n",
    "    random.shuffle(val_index)\n",
    "    random.shuffle(train_index)\n",
    "    return train_index, val_index, test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea diccionarios con los sets de datos\n",
    "train_index, val_index, test_index = get_sets_index(datos) #obtenemos los indices\n",
    "test_set={'images':[], 'im_21':[], 'labels':[], 'metadata':[]} #creacion diccionario con testing set\n",
    "val_set={'images':[], 'im_21':[], 'labels':[], 'metadata':[]} #creacion diccionario con validation set\n",
    "train_set={'images':[], 'im_21':[], 'labels':[], 'metadata':[]} #creacion diccionario con training set\n",
    "for i in range(len(train_index)): #añade los elementos de los indices de train_index al train_set\n",
    "    k=int(train_index[i])\n",
    "    train_set['images'].append(datos['images'][k])\n",
    "    train_set['im_21'].append(datos['im_21'][k])\n",
    "    train_set['labels'].append(datos['labels'][k])\n",
    "    train_set['metadata'].append(datos['metadata'][k])\n",
    "for i in range(len(val_index)): #añade los elementos de los indices de val_index al val_set\n",
    "    k=int(val_index[i])\n",
    "    val_set['images'].append(datos['images'][k])\n",
    "    val_set['im_21'].append(datos['im_21'][k])\n",
    "    val_set['labels'].append(datos['labels'][k])\n",
    "    val_set['metadata'].append(datos['metadata'][k])\n",
    "for i in range(len(test_index)): #añade los elementos de los indices de test_index al test_set\n",
    "    k=int(test_index[i])\n",
    "    test_set['images'].append(datos['images'][k])\n",
    "    test_set['im_21'].append(datos['im_21'][k])\n",
    "    test_set['labels'].append(datos['labels'][k])\n",
    "    test_set['metadata'].append(datos['metadata'][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write python dict to a file\n",
    "output = open('train_set.pkl', 'wb')\n",
    "pickle.dump(train_set, output)\n",
    "output.close()\n",
    "\n",
    "output = open('val_set.pkl', 'wb')\n",
    "pickle.dump(val_set, output)\n",
    "output.close()\n",
    "\n",
    "output = open('test_set.pkl', 'wb')\n",
    "pickle.dump(test_set, output)\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
